{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "recognized-clause",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "advance-plasma",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-national",
   "metadata": {},
   "source": [
    "## Gather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-preservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting base URL for the Pushift API to work with\n",
    "# url = 'https://api.pushshift.io/reddit/search/submission?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-potter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial parameters for requests to implement\n",
    "# params = {\n",
    "#         'subreddit': 'liberal',\n",
    "#         'size': 100\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-graduation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test gathering data from one pull from Pushift API\n",
    "# posts = requests.get(url, params).json()\n",
    "# df = pd.DataFrame(posts['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-radio",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['created_utc'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-mouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to pull 2500 submissions from our subreddit\n",
    "# def reddit_api(subreddit):\n",
    "#     # User only needs subreddit name as a string for input\n",
    "#     params = {\n",
    "#         'subreddit': subreddit,\n",
    "#         'size': 100\n",
    "#     }\n",
    "#     # Empty list to store scraped dataframes before combining\n",
    "#     df = []\n",
    "#     # Loop 25 times to pull 100 posts each loop: total 2500 posts\n",
    "#     while len(df) < 25:\n",
    "#         posts = requests.get(url, params).json()\n",
    "#         to_concat = pd.DataFrame(posts['data'])\n",
    "#         params['before'] = to_concat['created_utc'].min()\n",
    "#         df.append(to_concat)\n",
    "        \n",
    "#     return pd.concat(df, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-attempt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commented out because I keep accidentally running\n",
    "#lib = reddit_api('liberal')\n",
    "#con = reddit_api('conservative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-format",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save imports to access more easily later.\n",
    "# lib.to_csv('./data/r_liberal.csv', index=False)\n",
    "# con.to_csv('./data/r_conservative.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "rough-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib = pd.read_csv('./data/r_liberal.csv')\n",
    "con = pd.read_csv('./data/r_conservative.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "liable-helping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r/liberal duplicated\n",
      "\n",
      "False    2500\n",
      "Name: created_utc, dtype: int64\n",
      "-----------------------------------\n",
      "r/conservative duplicated\n",
      "\n",
      "False    2460\n",
      "True       40\n",
      "Name: created_utc, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking that our pull was successful with no significant duplicates\n",
    "print('r/liberal duplicated')\n",
    "print()\n",
    "print(lib['created_utc'].duplicated().value_counts())\n",
    "print('-----------------------------------')\n",
    "print('r/conservative duplicated')\n",
    "print()\n",
    "print(con['created_utc'].duplicated().value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preliminary-repair",
   "metadata": {},
   "source": [
    "## Begin EDA and data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "suitable-strength",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns=80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "raised-charity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_len(x,y):\n",
    "    if len(x.columns) < len(y.columns):\n",
    "        drop_columns = list(set(y) - set(x))\n",
    "    elif len(x.columns) > len(y.columns):\n",
    "        drop_columns = list(set(x) - set(y))\n",
    "\n",
    "    return drop_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "consolidated-primary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drops = col_len(lib, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "disciplinary-separate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# con = con.drop(columns=drops)\n",
    "# len(con.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "mobile-promise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('all_awardings', 0, 0),\n",
       " ('allow_live_comments', 0, 0),\n",
       " ('author', 0, 0),\n",
       " ('author_flair_css_class', 2500, 2500),\n",
       " ('author_flair_richtext', 106, 2409),\n",
       " ('author_flair_text', 2499, 245),\n",
       " ('author_flair_type', 106, 1441),\n",
       " ('author_fullname', 106, 1196),\n",
       " ('author_patreon_flair', 106, 245),\n",
       " ('author_premium', 106, 245),\n",
       " ('awarders', 0, 245),\n",
       " ('can_mod_post', 0, 245),\n",
       " ('contest_mode', 0, 0),\n",
       " ('created_utc', 0, 0),\n",
       " ('domain', 0, 0),\n",
       " ('full_link', 0, 0),\n",
       " ('gildings', 0, 0),\n",
       " ('id', 0, 0),\n",
       " ('is_crosspostable', 0, 0),\n",
       " ('is_meta', 0, 0),\n",
       " ('is_original_content', 0, 0),\n",
       " ('is_reddit_media_domain', 0, 0),\n",
       " ('is_robot_indexable', 0, 0),\n",
       " ('is_self', 0, 0),\n",
       " ('is_video', 0, 0),\n",
       " ('link_flair_background_color', 2500, 0),\n",
       " ('link_flair_richtext', 0, 0),\n",
       " ('link_flair_text_color', 0, 2500),\n",
       " ('link_flair_type', 0, 0),\n",
       " ('locked', 0, 0),\n",
       " ('media_only', 0, 0),\n",
       " ('no_follow', 0, 0),\n",
       " ('num_comments', 0, 2407),\n",
       " ('num_crossposts', 0, 0),\n",
       " ('over_18', 0, 0),\n",
       " ('parent_whitelist_status', 0, 0),\n",
       " ('permalink', 0, 0),\n",
       " ('pinned', 0, 0),\n",
       " ('pwls', 0, 0),\n",
       " ('removed_by_category', 563, 0),\n",
       " ('retrieved_on', 0, 0),\n",
       " ('score', 0, 0),\n",
       " ('selftext', 1394, 1274),\n",
       " ('send_replies', 0, 0),\n",
       " ('spoiler', 0, 0),\n",
       " ('stickied', 0, 2407),\n",
       " ('subreddit', 0, 2058),\n",
       " ('subreddit_id', 0, 0),\n",
       " ('subreddit_subscribers', 0, 0),\n",
       " ('subreddit_type', 0, 0),\n",
       " ('thumbnail', 0, 0),\n",
       " ('title', 0, 0),\n",
       " ('total_awards_received', 0, 0),\n",
       " ('treatment_tags', 0, 0),\n",
       " ('upvote_ratio', 0, 0),\n",
       " ('url', 0, 341),\n",
       " ('whitelist_status', 0, 341),\n",
       " ('wls', 0, 0),\n",
       " ('post_hint', 1146, 0),\n",
       " ('preview', 1146, 0),\n",
       " ('thumbnail_height', 1155, 0),\n",
       " ('thumbnail_width', 1155, 0),\n",
       " ('url_overridden_by_dest', 1083, 267),\n",
       " ('link_flair_text', 1908, 0),\n",
       " ('media', 2193, 0),\n",
       " ('media_embed', 2193, 1167),\n",
       " ('secure_media', 2193, 1167),\n",
       " ('secure_media_embed', 2193, 2423),\n",
       " ('link_flair_template_id', 2494, 2423),\n",
       " ('author_flair_background_color', 2500, 2359),\n",
       " ('author_flair_text_color', 2393, 2444),\n",
       " ('banned_by', 2465, 2465),\n",
       " ('crosspost_parent', 2493, 2497),\n",
       " ('crosspost_parent_list', 2493, 2493),\n",
       " ('edited', 2492, 2493),\n",
       " ('author_cakeday', 2492, 2499)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing null values between both subs\n",
    "# list(zip(lib.columns, lib.isnull().sum(), con.isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "established-virus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_concat(x, y):\n",
    "    keep_columns = ['subreddit', 'title',  'author', 'domain', 'id', 'num_comments', \n",
    "                'score', 'selftext', 'url']\n",
    "    df = pd.concat([lib, con], ignore_index=True)\n",
    "    df = df[keep_columns]\n",
    "    df['subreddit'] = df['subreddit'].apply(lambda x: 1 if x == 'Liberal' else 0)\n",
    "    df['title_word_count'] = [len(title.split()) for title in df['title']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cardiac-developer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>domain</th>\n",
       "      <th>id</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>selftext</th>\n",
       "      <th>url</th>\n",
       "      <th>title_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>On behalf of my neanderthal ancestors, I object!</td>\n",
       "      <td>MisanthropicScott</td>\n",
       "      <td>self.Liberal</td>\n",
       "      <td>ly2nha</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>https://www.reddit.com/r/Liberal/comments/ly2n...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>You Can't Change This Hatred—You Have to Outnu...</td>\n",
       "      <td>moochir</td>\n",
       "      <td>johnpavlovitz.com</td>\n",
       "      <td>lxy58f</td>\n",
       "      <td>19</td>\n",
       "      <td>181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://johnpavlovitz.com/2018/08/07/you-cant-...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Black teen fails all but 3 classes in 4 years ...</td>\n",
       "      <td>XiLin02</td>\n",
       "      <td>foxbaltimore.com</td>\n",
       "      <td>lxx3np</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://foxbaltimore.com/news/project-baltimor...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>How The Press Enables The GOP’s Big Lie</td>\n",
       "      <td>NORDLAN</td>\n",
       "      <td>nationalmemo.com</td>\n",
       "      <td>lxvws3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.nationalmemo.com/election-2020-lies-</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Russian State TV Is Really Missing Trump Now B...</td>\n",
       "      <td>NORDLAN</td>\n",
       "      <td>thedailybeast.com</td>\n",
       "      <td>lxvnt0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.thedailybeast.com/russian-state-tv...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit                                              title  \\\n",
       "0          1   On behalf of my neanderthal ancestors, I object!   \n",
       "1          1  You Can't Change This Hatred—You Have to Outnu...   \n",
       "2          1  Black teen fails all but 3 classes in 4 years ...   \n",
       "3          1            How The Press Enables The GOP’s Big Lie   \n",
       "4          1  Russian State TV Is Really Missing Trump Now B...   \n",
       "\n",
       "              author             domain      id  num_comments  score  \\\n",
       "0  MisanthropicScott       self.Liberal  ly2nha             0      1   \n",
       "1            moochir  johnpavlovitz.com  lxy58f            19    181   \n",
       "2            XiLin02   foxbaltimore.com  lxx3np             0      1   \n",
       "3            NORDLAN   nationalmemo.com  lxvws3             0      1   \n",
       "4            NORDLAN  thedailybeast.com  lxvnt0             2      5   \n",
       "\n",
       "    selftext                                                url  \\\n",
       "0  [removed]  https://www.reddit.com/r/Liberal/comments/ly2n...   \n",
       "1        NaN  https://johnpavlovitz.com/2018/08/07/you-cant-...   \n",
       "2        NaN  https://foxbaltimore.com/news/project-baltimor...   \n",
       "3        NaN   https://www.nationalmemo.com/election-2020-lies-   \n",
       "4        NaN  https://www.thedailybeast.com/russian-state-tv...   \n",
       "\n",
       "   title_word_count  \n",
       "0                 8  \n",
       "1                 9  \n",
       "2                23  \n",
       "3                 8  \n",
       "4                11  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = df_concat(lib, con)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "raised-arrival",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./data/subreddit_complete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-viewer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
